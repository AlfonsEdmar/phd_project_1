---
title: "Heterogenity in Psychology: a Mixed Methods Meta-Review using a Content Analysis and a Scoping Review"
author: "B.A Edmar"
format: pdf
editor: source
bibliography: prereg_draft_4_ref.bib
csl: apa.csl
---

\newpage

# 1. The Question

With this paper we aim to answer how heterogeneity impacts our assessment of evidence in systematic reviews and meta-analyses. At some point, the observed heterogeneity in a sample of effects becomes so large that the uncertainty of the inferences that can be made about a construct or theory is called into question. We want to get a better understanding of when this occurs in psychology. To do this we take a look at successful pooling of evidence in meta-analyses, but also at instances where pooling was not possible due to methodological diversity. With this two-pronged approach we aim to paint a nuanced picture of the line that separates qualitative and quantitative evidence synthesis; with the goal of gaining insight into how we can leverage past research for theory building in the present.

# 2. Background

Systematic reviews and meta-analyses are usually referred to as the gold standard of evidence, meaning that the synthesis of evidence is considered the strongest scientific case one can make for a certain theory or relationship between variables. The strength of these methods have their root in their use of multiple independent sources that together makes up a collection of results in which all available evidence can be taking into account when reaching a conclusion. However, taking all available evidence into account is not always easy or free from controversy. How exactly can we determine when different sources provide evidence for the same construct or theory? and when is a body of literature suitable for synthesis?

This question is explicitly or implicitly answered in the beginning stages of a review process, where the researchers define the eligibility criteria needed for studies to be included in the review. However, in some cases the body of literature of interest is not suitable for reviewing or meta-analytic pooling. This occurs when the methods used across studies are so varied that comparing them is not appropriate or possible. This is commonly referred to as the ''Apples and Oranges'' problem [@harrer_doing_2022] but is more precisely described as an issue of between-study heterogeneity. However, it should be noted that there are many interpretations to what we describe as between-study heterogeneity. In the following sections we will describe the main concepts relating to heterogeneity in evidence synthesis and detail key differences among them.

## 2.1 Heterogeneity

The strictest and most precise definition of heterogeneity is the variability of observed effects. That is, the variance within the pooled effect sizes of the studies included in the given meta-analysis. Explicitly, heterogeneity is the average squared distances from the mean of the true effect. This definition becomes an issue when the variation in effects is so large that their distribution is not indicative of coming from a single true value. In these cases, viewing the variance of an effect as purely stemming from random sampling is not appropriate. Thus, we make distinctions for situations when we assume that the total variation of effects is attributable to within study variation and when the total variation can be attributable to both between-study variation AND within-study variation. Hence forth, when we say heterogeneity we refer to the total variation in effects, regardless of whether we attribute it to within-study(sampling error) or between-study(heterogeneity) variance. The reason for doing this is that distinguishing between these sources in psychological settings is incredibly difficult since properly defining the "true" effects we are interested in is very hard [@shadish_experimental_2002]. Thus, what we mean by heterogeneity is the total variation of effect sizes expressed through the $\tau^2$ statistic. However, this is not as concrete as it might seem since there are multiple ways of estimating this statistic. In practice, how this estimation is done depends on the context of the study but it is generally advisable to try multiple estimators [@veroniki_methods_2016].

## 2.2 The Causes of Heterogeneity

With our definition of heterogeneity as the total variation of effects, we can add some nuance to its occurrence by viewing it as a counter-factual effect caused by some underlying factors. Exactly what these factors are will be dependent on the field of study you are in. Multiple guidelines and papers on how to approach heterogeneity when conducting evidence synthesis exist, and they use different terminology to refer to these sources [@noauthor_cochrane_nodate], [@li_definition_1995], [@weiss_conceptual_2014]. In general, sources of heterogeneity are categorised as stemming from the units under investigation or the methodology used to study those units. In psychology our units of study are almost exclusively humans and therefore all variability in effects attributable to differences in the humans we study is an example of heterogeneity being caused by the units under investigation. The way we study humans, be that through the design and context of experiments, measurements or modes of inference, is an example of heterogeneity being caused by methodological diversity. It should be noted that the presence of diversity, either in units or method, should not be seen as something that necessitate observed heterogeneity. However, whenever we observe heterogeneity, we must assume it to be caused by either underlying diversity in units and methodology, or through random sampling/variability.

# 3. Methods

This paper will consist of two dependent studies, one scoping review and one qualitative content analysis. A mixing procedure where the result from both studies are thematically synthesised to enrich the answer to our research question will also be conducted. It cannot be stressed enough that while there are surface level similarities between these two analyses, they are categorically different and their results cannot be directly compared. It is through the mixing procedure where an answer to the over-arching research question can be addressed. Simply put, we want to know when heterogeneity is an issue, but to properly answer this question we need to analyse when pooling data was judged to be mostly a statistical issue and when pooling data was judged to not be possible on qualitative grounds. We address the former with a scoping review and the latter with a qualitative content analysis. Figure 1 depicts a flow chart of how our overarching general research questions gets partitioned into more targeted research questions which require different modes of inquiry, and then how the results from both analyses are integrated to answer the initial question.

#### Figure 1: Design Flow Chart

![](design_flow_chart.png){fig-align="center" width="386"}

## 3.1 The Scoping Review

A scoping review is a type of evidence synthesis akin to a systematic review or a traditional literature review. The main difference between a systematic review and a scoping review is that the scoping review is a more iterative process designed to identify knowledge gaps, scope out a body of work, clarify concepts or investigate research conduct. As such, the synthesis of the scoping review is not designed to provide a summary of research findings from individual studies; but generate broader mapping of evidence, not unlike a traditional literature review.

Given that our goal is to clarify the concept of heterogeneity, and assess how the execution of research is impacted by the presence of heterogeneity, a scoping review is preferable to a systematic review [@munn_systematic_2018]. An alternative to a scoping review could be a rapid review; that being a feasibility constrained systematic review. However, it is not the feasibility of our investigation that informs our method - it is the underlying research question. Since we are mainly concerned with the qualia of heterogeneity, a quantitative assessment of the literature does not target the question; even though the literature itself is quantitative in nature.

This review will follow the guidelines provided by JBI to the greatest extent possible for the research question at hand [@noauthor_jbi_2020]. In essence, this means that an a priori protocol of the review including the exclusion criteria, search strategy, methodology and reporting will be conducted. One deviation from the recommendations will be present in the searching procedure due to the nature of the literature we are interested in. Since the JBI guidelines are compatible with the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews (PRISMA-ScR) [@tricco_prisma_2018], that reporting scheme will be followed in the manuscript.

### 3.1.1 Eligibility Criteria

To be included in the systematic scoping review, any document needs to be a meta-analysis within psychological science published in 2021 or 2022 to capture recently published studies. Additionally, documents must have a theoretical research question that requires the synthesis of evidence across multiple independent studies to be included. This means that studies posing meta-research questions will be excluded. An example of a meta-research question would be an evaluation of the prevalence of open-science practices or replications within a given field. The data within the documents must also have been generated through a systematic search of literature, this excludes sequential studies that aggregate their findings using an 'internal meta-analysis'.

In sum, for a study to be included in the scoping review it needs to: 1) be a meta-analysis conducted using standard literature search strategies; 2) cover a psychological concept; and 3) be published in 2021 or 2022.

### 3.1.2 Search Strategy

The JBI [@noauthor_jbi_2020] guidelines state that at least two databases should be subject to an initial search, thereafter a second search using all identified keywords should be conducted, and then the reference list of all identified sources should be consulted for additional documents. While these guidelines are sound, following this strategy is not feasible in our case due to the breadth of the literature we are interested in. Therefore we deviate from the JBI manual in this area.

Since the field we are interested in is psychology, searching databases outside psychology will have to include field limitations that would not be needed in psychology specific data bases such as PsychInfo. Therefore, we will only search PsychInfo, since that database provides us with a natural exclusion of documents outside the field of psychology. As an extension of this strategy we use APA classification categories to get a representative sample of papers across the many sub-fields within psychology. To this end we limit our search to papers within the following categories: Physiological Psychology & Neuroscience (2500), Developmental Psychology (2800), Social Psychology (3000), Personality Psychology (3100), Organizational Psychology (3600), Forensic psychology & Legal Issues (4200). These categories are selected to ensure that a representative sample of different areas of psychology are searched for while limiting the number of search results. Table 1 depicts the iterative searches done through the search engine Ovid and shows how the number of results are reduced as limitations are put on the search terms.

#### Table 1

|     | Search Terms                                                                                                                                                                                                                                       | Results |
|-----------------|--------------------------------------|-----------------|
| 1   | meta-analy\* or meta analy\*{Including Related Terms}                                                                                                                                                                                              | 30 330  |
| 2   | limit 1 to (2500 physiological psychology & neuroscience or 2800 developmental psychology or 3000 social psychology or 3100 personality psychology or 3600 organizational psychology & human resources or 4200 forensic psychology & legal issues) | 1188    |
| 3   | limit 2 to yr="2021 - 2022"                                                                                                                                                                                                                        | 201     |

### 3.1.3 Document Screening and Selection

The identified documents was screened using the software tool rayyan.ai, the main purpose of this was to utilise the rayyan screening environment and thus we did not use any automated tools. The screening was conducted in a two stage fashion where the abstracts from the initial search was screened for eligibility. After locating eligible studies, a stratified random selection of 5 studies from each of the six APA classification categories was conducted to get a total sample of 30. However, only 3 of the 5 studies selected from the Personality Psychology category could be located, which gave us a final sample of 28 articles. An over view of the entire search and selection procedure can be seen in the PRISMA floc chart in figure 2.

\newpage

#### Figure 2: PRISMA Flow Chart

![](prisma_flow.png){fig-align="center" width="386"}

### 3.1.4 Data Extraction

The data from the identified studies will be extracted into an excel code book based on an a priori constructed extraction instrument as is proper for scoping reviews [@munn_systematic_2018]. The extraction instrument is designed to answer a series of research questions derived from potential sources of heterogeneity based on the four Cambellian validities [@shadish_experimental_2002]. The code book covers three main themes: general study characteristics, the presence of heterogeneity in the review, and how the authors dealt with the observed statistical heterogeneity. Across these three themes we will include notation of the aims of the study, the sub-field of the study, the population examined, the methodology used, exclusion criteria, findings/conclusion of the study, etc. The extraction instrument can be seen in its entirety in appendix A.

### 3.1.5 Data Analysis

The analysis of the data will consist of summarizing the motivation for the various choices made in the individual data points. These results will be presented with simple descriptive statistics but also with a qualitative analysis of how authors reason about their analysis choices and exclusion criteria with regards to heterogeneity. These results will then be compared across sub-fields to see if the practice of adjusting for heterogeneity varies dependent on the field. The qualitative analysis will aim to be descriptive and will not seek to find any emergent or latent themes within the data. The result will be an evidence map of how heterogeneity is accounted for in the exclusion criteria and the theory under investigation as well as how the statistical heterogeneity is handled by the authors.

## 3.2 The Qualitative Content Analysis

While we have a similar goal with our content analysis as with our scoping review, these methodologies are different from one another. In a content analysis, no systematic protocol is needed, and no synthesis of evidence is conducted. Instead, a fully qualitative approach is taken where the results of the analysis cannot be fully divorced from it's author(s), meaning that its reproducibility is weak. This does not mean that transparency falls by the wayside or that measures to ensure inter-rater-agreement is reduced, but rather that the point of the analysis is not to give a systematically reproducible analysis of a literature.

A content analysis, as described by @elo_qualitative_2014, can be defined as "A flexible method for making valid inferences from data in order to provide new insight, describe a phenomenon through concepts or categories, and develop an understanding of the meaning of communications with a concern for intentions, consequences, and context." This makes it an apt method for our purposes since we aim to find cases of reported problematic heterogeneity in systematic reviews. We mean to locate instances where the apparent goal of the review is to pool data for a meta-analysis but the perceived heterogeneity was too large for a valid synthesis. That is, we are specifically looking of reviews that mention aspirations of meta-analytic pooling, but due to a high degree of diversity in methodology or units, that could not be done.

In order to make valid inferences about this phenomenon, we need to take context, intentions and communication from the authors conducting the study into account, thereby making a qualitative content analysis an appropriate method.

### 3.2.1 Search for Secondary Sources

To locate studies of this kind, a search for literature similar to that of the scoping review was conducted, with the addition of searching for heterogeneity in the abstracts, titles, or keywords. Since the only type of heterogeneity present within systematic reviews is non-statistical, this additional keyword helped us locate instances where the heterogeneity of the study population was challengingly high. No eligibility criteria for inclusion exists, this search procedure is simply a means of generating data from secondary sources and should not be confused with a systematic literature search. Thus, the search period was loosened to include studies published after 2017 in order to capture current research without being constrained to particular years as was done in the scoping review. On October 18th, the following search was conducted using the terms and limitations provided in table 2.

#### Table 2

|     |                                                                                                                                                                                                                                                    |             |
|-----------------|--------------------------------------|-----------------|
|     | **Search terms**                                                                                                                                                                                                                                   | **Results** |
| 1   | systematic review AND heterogeneity {Including Related Terms}                                                                                                                                                                                      | 33 783      |
| 2   | limit 1 to (2500 physiological psychology & neuroscience or 2800 developmental psychology or 3000 social psychology or 3100 personality psychology or 3600 organizational psychology & human resources or 4200 forensic psychology & legal issues) | 2373        |
| 3   | limit 2 to yr="2018 -Current"                                                                                                                                                                                                                      | 955         |

A screening of the 955 documents on November first 2023 found 14 documents to be suitable for analysis since they indicated aspiration of mathematical synthesis but, due to high between-study heterogeneity was not possible.

### 3.2.2 Methodology

The qualitative content analysis will be conducted using an inductive analysis with a critical realist framework. However, since the topic under investigation has a long history of study, we will be using the theoretical scaffolding of heterogeneity typology and the considerable work on validity stemming from the philosophy of science [@shadish_experimental_2002], thus the study will not be purely inductive. That is, we will be using a deductive-inductive approach [@hong_convergent_2017].

The analysis will follow the standard procedure of identifying studies, immersing oneself within the data, and developing the codebook as an information saturated picture of the concept under study is painted [@cho_reducing_2014]. However, three initial categories consisting of external, internal, and construct validity will be taken from the extraction instrument of the scoping review in order to structure the codes. This will in turn allow us to create a categorisation matrix where we can bolster inter-rater agreement and provide a semblance of systematic objectivity in the coding of the articles. These categories also serve as an a priori Epoch√© (Bracketing) of what code categories we expect to find in the systematic reviews. Through this we aim to ground the analysis in theory as well as provide some transparency regarding the authors motivation and expectations from the analysis.

After coding the articles and assigning the codes to our pre-defined categories, the hermeneutic-circle will be employed to redefine the categories and create new ones where needed. This will be done to extract as much information as possible from the systematic reviews and provide more nuance to the issue of heterogeneity in those types of evidence syntheses. This specific procedure is selected to suit our research question and the overall purpose of this paper. However, It should be noted that no absolute guidelines for how to conduct a qualitative content analysis exists, making it a flexible but challenging research method [@hong_convergent_2017].

## 3.3 Mixing

Following the guidelines provided by JBI [@noauthor_jbi_2020], the mixing procedure will follow a convergent design where each study informs the other to answer our singular research question of how heterogeneity hinders evidence synthesis. We will utilise a 'qualitising' transformation where the evidence map from the scoping review will be integrated into the categories identified in the qualitative analysis [@thomas_methods_2008], [@hong_convergent_2017]. This will provide us with a thematic synthesis that can highlight the issues posed by the presence of heterogeneity in the assessment of evidence, both from a qualitative and quantitative perspective.

\newpage

# References
