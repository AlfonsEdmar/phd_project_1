
@article{linden_heterogeneity_2021,
	title = {Heterogeneity of {Research} {Results}: {A} {New} {Perspective} {From} {Which} to {Assess} and {Promote} {Progress} in {Psychological} {Science}},
	volume = {16},
	issn = {1745-6916, 1745-6924},
	shorttitle = {Heterogeneity of {Research} {Results}},
	url = {http://journals.sagepub.com/doi/10.1177/1745691620964193},
	doi = {10.1177/1745691620964193},
	abstract = {Heterogeneity emerges when multiple close or conceptual replications on the same subject produce results that vary more than expected from the sampling error. Here we argue that unexplained heterogeneity reflects a lack of coherence between the concepts applied and data observed and therefore a lack of understanding of the subject matter. Typical levels of heterogeneity thus offer a useful but neglected perspective on the levels of understanding achieved in psychological science. Focusing on continuous outcome variables, we surveyed heterogeneity in 150 meta-analyses from cognitive, organizational, and social psychology and 57 multiple close replications. Heterogeneity proved to be very high in meta-analyses, with powerful moderators being conspicuously absent. Population effects in the average meta-analysis vary from small to very large for reasons that are typically not understood. In contrast, heterogeneity was moderate in close replications. A newly identified relationship between heterogeneity and effect size allowed us to make predictions about expected heterogeneity levels. We discuss important implications for the formulation and evaluation of theories in psychology. On the basis of insights from the history and philosophy of science, we argue that the reduction of heterogeneity is important for progress in psychology and its practical applications, and we suggest changes to our collective research practice toward this end.},
	language = {en},
	number = {2},
	urldate = {2023-09-29},
	journal = {Perspectives on Psychological Science},
	author = {Linden, Audrey Helen and Hönekopp, Johannes},
	month = mar,
	year = {2021},
	pages = {358--376},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\BH8UMCBA\\Linden and Hönekopp - 2021 - Heterogeneity of Research Results A New Perspecti.pdf:application/pdf},
}

@book{noauthor_jbi_2020,
	title = {{JBI} {Manual} for {Evidence} {Synthesis}},
	isbn = {978-0-648-84880-6},
	url = {https://jbi-global-wiki.refined.site/space/MANUAL},
	urldate = {2023-09-29},
	publisher = {JBI},
	year = {2020},
	doi = {10.46658/JBIMES-20-01},
}

@article{peters_guidance_2015,
	title = {Guidance for conducting systematic scoping reviews},
	volume = {13},
	issn = {1744-1609},
	url = {https://journals.lww.com/01787381-201509000-00005},
	doi = {10.1097/XEB.0000000000000050},
	language = {en},
	number = {3},
	urldate = {2023-09-29},
	journal = {International Journal of Evidence-Based Healthcare},
	author = {Peters, Micah D.J. and Godfrey, Christina M. and Khalil, Hanan and McInerney, Patricia and Parker, Deborah and Soares, Cassia Baldini},
	month = sep,
	year = {2015},
	pages = {141--146},
}

@article{munn_systematic_2018,
	title = {Systematic review or scoping review? {Guidance} for authors when choosing between a systematic or scoping review approach},
	volume = {18},
	issn = {1471-2288},
	shorttitle = {Systematic review or scoping review?},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-018-0611-x},
	doi = {10.1186/s12874-018-0611-x},
	language = {en},
	number = {1},
	urldate = {2023-09-29},
	journal = {BMC Medical Research Methodology},
	author = {Munn, Zachary and Peters, Micah D. J. and Stern, Cindy and Tufanaru, Catalin and McArthur, Alexa and Aromataris, Edoardo},
	month = dec,
	year = {2018},
	pages = {143},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\WXE9MJTR\\Munn et al. - 2018 - Systematic review or scoping review Guidance for .pdf:application/pdf},
}

@incollection{higgins_defining_2019,
	edition = {1},
	title = {Defining the criteria for including studies and how they will be grouped for the synthesis},
	isbn = {978-1-119-53662-8 978-1-119-53660-4},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/9781119536604.ch3},
	language = {en},
	urldate = {2023-09-29},
	booktitle = {Cochrane {Handbook} for {Systematic} {Reviews} of {Interventions}},
	publisher = {Wiley},
	author = {McKenzie, Joanne E and Brennan, Sue E and Ryan, Rebecca E and Thomson, Hilary J and Johnston, Renea V and Thomas, James},
	editor = {Higgins, Julian P.T. and Thomas, James and Chandler, Jacqueline and Cumpston, Miranda and Li, Tianjing and Page, Matthew J. and Welch, Vivian A.},
	month = sep,
	year = {2019},
	doi = {10.1002/9781119536604.ch3},
	pages = {33--65},
}

@incollection{noauthor_chapter_2020,
	title = {Chapter 11: {Scoping} reviews},
	isbn = {978-0-648-84880-6},
	shorttitle = {Chapter 11},
	url = {https://jbi-global-wiki.refined.site/space/MANUAL/4687342/Chapter+11%3A+Scoping+reviews},
	urldate = {2023-10-08},
	booktitle = {{JBI} {Manual} for {Evidence} {Synthesis}},
	publisher = {JBI},
	year = {2020},
	doi = {10.46658/JBIMES-20-12},
}

@article{tricco_prisma_2018,
	title = {{PRISMA} {Extension} for {Scoping} {Reviews} ({PRISMA}-{ScR}): {Checklist} and {Explanation}},
	volume = {169},
	issn = {0003-4819, 1539-3704},
	shorttitle = {{PRISMA} {Extension} for {Scoping} {Reviews} ({PRISMA}-{ScR})},
	url = {https://www.acpjournals.org/doi/10.7326/M18-0850},
	doi = {10.7326/M18-0850},
	language = {en},
	number = {7},
	urldate = {2023-10-08},
	journal = {Annals of Internal Medicine},
	author = {Tricco, Andrea C. and Lillie, Erin and Zarin, Wasifa and O'Brien, Kelly K. and Colquhoun, Heather and Levac, Danielle and Moher, David and Peters, Micah D.J. and Horsley, Tanya and Weeks, Laura and Hempel, Susanne and Akl, Elie A. and Chang, Christine and McGowan, Jessie and Stewart, Lesley and Hartling, Lisa and Aldcroft, Adrian and Wilson, Michael G. and Garritty, Chantelle and Lewin, Simon and Godfrey, Christina M. and Macdonald, Marilyn T. and Langlois, Etienne V. and Soares-Weiser, Karla and Moriarty, Jo and Clifford, Tammy and Tunçalp, Özge and Straus, Sharon E.},
	month = oct,
	year = {2018},
	pages = {467--473},
	file = {Accepted Version:C\:\\Users\\Edmar001\\Zotero\\storage\\GUYD3FHS\\Tricco et al. - 2018 - PRISMA Extension for Scoping Reviews (PRISMA-ScR).pdf:application/pdf},
}

@article{lorenc_meta-analysis_2016,
	title = {Meta-analysis, complexity, and heterogeneity: a qualitative interview study of researchers’ methodological values and practices},
	volume = {5},
	issn = {2046-4053},
	shorttitle = {Meta-analysis, complexity, and heterogeneity},
	url = {http://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-016-0366-6},
	doi = {10.1186/s13643-016-0366-6},
	language = {en},
	number = {1},
	urldate = {2023-10-17},
	journal = {Systematic Reviews},
	author = {Lorenc, Theo and Felix, Lambert and Petticrew, Mark and Melendez-Torres, G J and Thomas, James and Thomas, Sian and O’Mara-Eves, Alison and Richardson, Michelle},
	month = dec,
	year = {2016},
	pages = {192},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\99R6FLG8\\Lorenc et al. - 2016 - Meta-analysis, complexity, and heterogeneity a qu.pdf:application/pdf},
}

@article{elo_qualitative_2014,
	title = {Qualitative {Content} {Analysis}: {A} {Focus} on {Trustworthiness}},
	volume = {4},
	issn = {2158-2440, 2158-2440},
	shorttitle = {Qualitative {Content} {Analysis}},
	url = {http://journals.sagepub.com/doi/10.1177/2158244014522633},
	doi = {10.1177/2158244014522633},
	abstract = {Qualitative content analysis is commonly used for analyzing qualitative data. However, few articles have examined the trustworthiness of its use in nursing science studies. The trustworthiness of qualitative content analysis is often presented by using terms such as credibility, dependability, conformability, transferability, and authenticity. This article focuses on trustworthiness based on a review of previous studies, our own experiences, and methodological textbooks. Trustworthiness was described for the main qualitative content analysis phases from data collection to reporting of the results. We concluded that it is important to scrutinize the trustworthiness of every phase of the analysis process, including the preparation, organization, and reporting of results. Together, these phases should give a reader a clear indication of the overall trustworthiness of the study. Based on our findings, we compiled a checklist for researchers attempting to improve the trustworthiness of a content analysis study. The discussion in this article helps to clarify how content analysis should be reported in a valid and understandable manner, which would be of particular benefit to reviewers of scientific articles. Furthermore, we discuss that it is often difficult to evaluate the trustworthiness of qualitative content analysis studies because of defective data collection method description and/or analysis description.},
	language = {en},
	number = {1},
	urldate = {2023-10-18},
	journal = {SAGE Open},
	author = {Elo, Satu and Kääriäinen, Maria and Kanste, Outi and Pölkki, Tarja and Utriainen, Kati and Kyngäs, Helvi},
	month = jan,
	year = {2014},
	pages = {215824401452263},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\852EPJTQ\\Elo et al. - 2014 - Qualitative Content Analysis A Focus on Trustwort.pdf:application/pdf},
}

@book{shadish_experimental_2002,
	address = {Boston,  MA,  US},
	series = {Experimental and quasi-experimental designs for generalized causal inference.},
	title = {Experimental and quasi-experimental designs for generalized causal inference.},
	isbn = {0-395-61556-9 (Paperback)},
	abstract = {This is a book for those who have already decided that identifying a dependable relationship between a cause and its effects is a high priority and who wish to consider experimental methods for doing so. Such causal relationships are of great importance in human affairs. The rewards associated with being correct in identifying causal relationships can be high, an the costs of misidentification can be tremendous. This book has two major purposes: to describe ways in which testing causal propositions can be improved in specific research projects, and to describe ways to improve generalizations about causal propositions. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Houghton, Mifflin and Company},
	author = {Shadish, William R. and Cook, Thomas D. and Campbell, Donald T.},
	year = {2002},
	note = {Pages: xxi, 623},
	keywords = {*Causal Analysis, *Experimental Design, *Experimental Methods, Quasi Experimental Methods},
}

@article{kahneman_when_1993,
	title = {When {More} {Pain} {Is} {Preferred} to {Less}: {Adding} a {Better} {End}},
	volume = {4},
	issn = {0956-7976, 1467-9280},
	shorttitle = {When {More} {Pain} {Is} {Preferred} to {Less}},
	url = {http://journals.sagepub.com/doi/10.1111/j.1467-9280.1993.tb00589.x},
	doi = {10.1111/j.1467-9280.1993.tb00589.x},
	abstract = {Subjects were exposed to two aversive experiences: in the short trial, they immersed one hand in water at 14 °C for 60 s; in the long trial, they immersed the other hand at 14 °C for 60 s, then kept the hand in the water 30 s longer as the temperature of the water was gradually raised to 15 °C, still painful but distinctly less so for most subjects. Subjects were later given a choice of which trial to repeat. A significant majority chose to repeat the long trial, apparently preferring more pain over less. The results add to other evidence suggesting that duration plays a small role in retrospective evaluations of aversive experiences; such evaluations are often dominated by the discomfort at the worst and at the final moments of episodes.},
	language = {en},
	number = {6},
	urldate = {2023-10-18},
	journal = {Psychological Science},
	author = {Kahneman, Daniel and Fredrickson, Barbara L. and Schreiber, Charles A. and Redelmeier, Donald A.},
	month = nov,
	year = {1993},
	pages = {401--405},
}

@article{higgins_quantifying_2002,
	title = {Quantifying heterogeneity in a meta‐analysis},
	volume = {21},
	issn = {0277-6715, 1097-0258},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/sim.1186},
	doi = {10.1002/sim.1186},
	abstract = {Abstract
            
              The extent of heterogeneity in a meta‐analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between‐study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta‐analysis. We develop measures of the impact of heterogeneity on a meta‐analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics:
              H
              is the square root of the χ
              2
              heterogeneity statistic divided by its degrees of freedom;
              R
              is the ratio of the standard error of the underlying mean from a random effects meta‐analysis to the standard error of a fixed effect meta‐analytic estimate, and
              I
              2
              is a transformation of
              H
              that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that
              H
              and
              I
              2
              , which can usually be calculated for published meta‐analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta‐analyses in preference to the test for heterogeneity. Copyright © 2002 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {11},
	urldate = {2023-10-19},
	journal = {Statistics in Medicine},
	author = {Higgins, Julian P. T. and Thompson, Simon G.},
	month = jun,
	year = {2002},
	pages = {1539--1558},
}

@article{cho_reducing_2014,
	title = {Reducing {Confusion} about {Grounded} {Theory} and {Qualitative} {Content} {Analysis}: {Similarities} and {Differences}},
	issn = {2160-3715, 1052-0147},
	shorttitle = {Reducing {Confusion} about {Grounded} {Theory} and {Qualitative} {Content} {Analysis}},
	url = {https://nsuworks.nova.edu/tqr/vol19/iss32/2/},
	doi = {10.46743/2160-3715/2014.1028},
	abstract = {Although grounded theory and qualitative content analysis are similar in some respects, they differ as well; yet the differences between the two have rarely been made clear in the literature. The purpose of this article was to clarify ambiguities and reduce confusion about grounded theory and qualitative content analysis by identifying similarities and differences in the two based on a literature review and critical reflection on the authors’ own research. Six areas of difference emerged: (a) background and philosophical base, (b) unique characteristics of each method, (c) goals and rationale of each method, (d) data analysis process, (e) outcomes of the research, and (f) evaluation of trustworthiness. This article provides knowledge that can assist researchers and students in the selection of appropriate research methods for their inquiries.},
	language = {en},
	urldate = {2023-10-25},
	journal = {The Qualitative Report},
	author = {Cho, Ji and Lee, Eun-Hee},
	month = oct,
	year = {2014},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\YPEI69R6\\Cho and Lee - 2014 - Reducing Confusion about Grounded Theory and Quali.pdf:application/pdf},
}

@article{weiss_conceptual_2014,
	title = {A {CONCEPTUAL} {FRAMEWORK} {FOR} {STUDYING} {THE} {SOURCES} {OF} {VARIATION} {IN} {PROGRAM} {EFFECTS}},
	volume = {33},
	issn = {0276-8739, 1520-6688},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/pam.21760},
	doi = {10.1002/pam.21760},
	abstract = {Abstract
            Evaluations of public programs in many fields reveal that different types of programs—or different versions of the same program—vary in their effectiveness. Moreover, a program that is effective for one group of people might not be effective for other groups, and a program that is effective in one set of circumstances may not be effective in other circumstances. This paper presents a conceptual framework for research on such variation in program effects and the sources of this variation. The framework is intended to help researchers—both those who focus mainly on studying program implementation and those who focus mainly on estimating program effects—see how their respective pieces fit together in a way that helps to identify factors that explain variation in program effects, and thereby support more systematic data collection. The ultimate goal of the framework is to enable researchers to offer better guidance to policymakers and program operators on the conditions and practices that are associated with larger and more positive effects.},
	language = {en},
	number = {3},
	urldate = {2023-10-25},
	journal = {Journal of Policy Analysis and Management},
	author = {Weiss, Michael J. and Bloom, Howard S. and Brock, Thomas},
	month = jun,
	year = {2014},
	pages = {778--808},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\M2PSABCJ\\Weiss et al. - 2014 - A CONCEPTUAL FRAMEWORK FOR STUDYING THE SOURCES OF.pdf:application/pdf},
}

@article{li_definition_1995,
	title = {On {Definition} and {Quantification} of {Heterogeneity}},
	volume = {73},
	issn = {00301299},
	url = {https://www.jstor.org/stable/3545921?origin=crossref},
	doi = {10.2307/3545921},
	number = {2},
	urldate = {2023-10-25},
	journal = {Oikos},
	author = {Li, H. and Reynolds, J. F.},
	month = jun,
	year = {1995},
	pages = {280},
}

@misc{noauthor_cochrane_2019,
	title = {Cochrane {Handbook} for {Systematic} {Reviews} of {Interventions}},
	url = {https://training.cochrane.org/handbook},
	abstract = {This Handbook outlines in detail Cochrane's methods for conducting systematic reviews of interventions, including planning, literature searching, assessing bias},
	language = {en},
	urldate = {2023-10-25},
	year = {2019},
	annote = {Higgins JPT, Thomas J, Chandler J, Cumpston M, Li T, Page MJ, Welch VA (editors). Cochrane Handbook for Systematic Reviews of Interventions version 6.4 (updated August 2023). Cochrane, 2023. Available from www.training.cochrane.org/handbook.},
	file = {Snapshot:C\:\\Users\\Edmar001\\Zotero\\storage\\XEVGR4TF\\handbook.html:text/html},
}

@incollection{noauthor_chapter_2020-1,
	title = {Chapter 8: {Mixed} methods systematic reviews},
	isbn = {978-0-648-84880-6},
	shorttitle = {Chapter 8},
	url = {https://jbi-global-wiki.refined.site/space/MANUAL/4687380/Chapter+8%3A+Mixed+methods+systematic+reviews},
	urldate = {2023-10-25},
	booktitle = {{JBI} {Manual} for {Evidence} {Synthesis}},
	publisher = {JBI},
	year = {2020},
	doi = {10.46658/JBIMES-20-09},
}

@article{thomas_methods_2008,
	title = {Methods for the thematic synthesis of qualitative research in systematic reviews},
	volume = {8},
	issn = {1471-2288},
	url = {https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/1471-2288-8-45},
	doi = {10.1186/1471-2288-8-45},
	language = {en},
	number = {1},
	urldate = {2023-10-25},
	journal = {BMC Medical Research Methodology},
	author = {Thomas, James and Harden, Angela},
	month = dec,
	year = {2008},
	pages = {45},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\787BQSCH\\Thomas and Harden - 2008 - Methods for the thematic synthesis of qualitative .pdf:application/pdf},
}

@article{hong_convergent_2017,
	title = {Convergent and sequential synthesis designs: implications for conducting and reporting systematic reviews of qualitative and quantitative evidence},
	volume = {6},
	issn = {2046-4053},
	shorttitle = {Convergent and sequential synthesis designs},
	url = {http://systematicreviewsjournal.biomedcentral.com/articles/10.1186/s13643-017-0454-2},
	doi = {10.1186/s13643-017-0454-2},
	language = {en},
	number = {1},
	urldate = {2023-10-25},
	journal = {Systematic Reviews},
	author = {Hong, Quan Nha and Pluye, Pierre and Bujold, Mathieu and Wassef, Maggy},
	month = dec,
	year = {2017},
	pages = {61},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\RQMI74DD\\Hong et al. - 2017 - Convergent and sequential synthesis designs impli.pdf:application/pdf},
}

@article{veroniki_methods_2016,
	title = {Methods to estimate the between‐study variance and its uncertainty in meta‐analysis},
	volume = {7},
	issn = {1759-2879, 1759-2887},
	url = {https://onlinelibrary.wiley.com/doi/10.1002/jrsm.1164},
	doi = {10.1002/jrsm.1164},
	abstract = {Meta‐analyses are typically used to estimate the overall/mean of an outcome of interest. However, inference about between‐study variability, which is typically modelled using a between‐study variance parameter, is usually an additional aim. The DerSimonian and Laird method, currently widely used by default to estimate the between‐study variance, has been long challenged. Our aim is to identify known methods for estimation of the between‐study variance and its corresponding uncertainty, and to summarise the simulation and empirical evidence that compares them. We identified 16 estimators for the between‐study variance, seven methods to calculate confidence intervals, and several comparative studies. Simulation studies suggest that for both dichotomous and continuous data the estimator proposed by Paule and Mandel and for continuous data the restricted maximum likelihood estimator are better alternatives to estimate the between‐study variance. Based on the scenarios and results presented in the published studies, we recommend the Q‐profile method and the alternative approach based on a ‘generalised Cochran between‐study variance statistic’ to compute corresponding confidence intervals around the resulting estimates. Our recommendations are based on a qualitative evaluation of the existing literature and expert consensus. Evidence‐based recommendations require an extensive simulation study where all methods would be compared under the same scenarios. © 2015 The Authors.
              Research Synthesis Methods
              published by John Wiley \& Sons Ltd.},
	language = {en},
	number = {1},
	urldate = {2023-11-29},
	journal = {Research Synthesis Methods},
	author = {Veroniki, Areti Angeliki and Jackson, Dan and Viechtbauer, Wolfgang and Bender, Ralf and Bowden, Jack and Knapp, Guido and Kuss, Oliver and Higgins, Julian PT and Langan, Dean and Salanti, Georgia},
	month = mar,
	year = {2016},
	pages = {55--79},
	file = {Full Text:C\:\\Users\\Edmar001\\Zotero\\storage\\BAXMFP48\\Veroniki et al. - 2016 - Methods to estimate the between‐study variance and.pdf:application/pdf},
}

@book{harrer_doing_2022,
	address = {Boca Raton},
	edition = {First edition},
	title = {Doing meta-analysis with {R}: a hands-on guide},
	isbn = {978-1-00-310734-7},
	shorttitle = {Doing meta-analysis with {R}},
	abstract = {"This book serves as an accessible introduction into how meta-analyses can be conducted in R. Essential steps for meta-analysis are covered, including pooling of outcome measures, forest plots, heterogeneity diagnostics, subgroup analyses, meta-regression, methods to control for publication bias, risk of bias assessments and plotting tools. Advanced, but highly relevant topics such as network meta-analysis, multi-/three-level meta-analyses, Bayesian meta-analysis approaches, SEM meta-analysis are also covered. A companion R package, dmetar, is introduced in the beginning of the guide. It contains data sets and several helper functions for the meta and metafor package used in the guide"--},
	publisher = {CRC Press},
	author = {Harrer, Mathias},
	year = {2022},
	keywords = {Meta-analysis, R (Computer program language)},
}

@article{macklin_what_2022,
	title = {What does it mean for an evaluation to be ‘valid’? {A} critical synthesis of evaluation literature},
	volume = {91},
	issn = {01497189},
	shorttitle = {What does it mean for an evaluation to be ‘valid’?},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149718922000106},
	doi = {10.1016/j.evalprogplan.2022.102056},
	language = {en},
	urldate = {2023-12-07},
	journal = {Evaluation and Program Planning},
	author = {Macklin, Jennifer and Gullickson, Amy M.},
	month = apr,
	year = {2022},
	pages = {102056},
}

@article{lucas_theory-testing_2003,
	title = {Theory-{Testing}, {Generalization}, and the {Problem} of {External} {Validity}},
	volume = {21},
	issn = {0735-2751, 1467-9558},
	url = {http://journals.sagepub.com/doi/10.1111/1467-9558.00187},
	doi = {10.1111/1467-9558.00187},
	abstract = {External validity refers to the generalization of research findings, either from a sample to a larger population or to settings and populations other than those studied. While definitions vary, discussions generally agree that experiments are lower in external validity than other methodological approaches. Further, external validity is widely treated as an issue to be addressed through methodological procedures. When testing theories, all measures are indirect indicators of theoretical constructs, and no methodological procedures taken alone can produce external validity. External validity can be assessed through determining (1) the extent to which empirical measures accurately reflect theoretical constructs, (2) whether the research setting conforms to the scope of the theory under test, (3) our confidence that findings will repeat under identical conditions, (4) whether findings support the theory being tested, and (5) the confirmatory status of the theory under test. In these ways, external validity is foremost a theoretical issue and can only be addressed by an examination of the interplay between theory and methods.},
	language = {en},
	number = {3},
	urldate = {2023-12-14},
	journal = {Sociological Theory},
	author = {Lucas, Jeffrey W.},
	month = sep,
	year = {2003},
	pages = {236--253},
}
