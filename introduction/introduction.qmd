---
title: "Introduction"
author: "B.A EDMAR"
format: html
editor: source
---
# The Question

With this paper we aim to answer how heterogeneity impacts our assessment of evidence in systematic reviews and meta-analyses. We want to examine how issues in comparability across studies are expressed through their external, internal, statistical and construct validity. More specifically, we want to examine the problems in pooling effects across diverse studies and how researchers deal with problematic heterogeneity. Another way to phrase this question could be: at what point are qualitative differences between scientific inquiries into the same underlying psychological construct large enough that we conclude that the latent effects we are measuring are different; regardless of whether statistical evidence of that is present?

To answer this question we will conduct two dependent studies, a qualitative content analysis and a scoping review. These will follow a convergent mixed methods design where both will be conducted in parallel and integrated using a thematic synthesis to provide nuanced results.

# Background

Systematic reviews and meta-analysis are usually referred to as the gold standard of evidence based inference, meaning that the synthesis of evidence from multiple sources are considered the strongest scientific case one can make for a certain theory. The strength of these methods have their root in their use of multiple independent sources that together provides a nuanced picture where all available evidence can be taking into account when reaching a conclusion. However, taking all available evidence into account is not always easy or free from controversy. How exactly can we determine when different sources provide evidence for the same construct or theory? and when is a body of literature suitable for synthesis.

This question is explicitly or implicitly answered in the beginning stages of a review process, where the researchers define the eligibility criteria needed for studies to be included in the review. However, in some cases, the body of literature that is of interest is not suitable for meta-analytic pooling. This occurs when the methods used across studies are so varied that comparing them is not appropriate or possible. This is commonly referred to as the ''Apples and Oranges'' problem(REF Harrer)but is more precisely described as an issue of between-study heterogeneity. However, it should be noted that there are many nuances to what we describe as study heterogeneity, comparability or diversity. In the following sections we will describe key concepts in evidence synthesis and detail key differences among them that sets the foundation of our study.

# Heterogeneity

The strictest and most precise definition of heterogeneity is the variability of observed effects. That is, the variance within the pooled effect sizes of the studies included in the given meta-analysis. Explicitly, heterogeneity is the average squared distances from the mean of the true effect. This definition becomes an issue when the variation in effects is so large that their distribution is not indicative of coming from a single true value. In these cases, viewing the variance of an effect as purely stemming from random sampling is not appropriate. Thus, we make distinctions for situations when we assume that the total variation of effects is attributable to within study variation and when the total variation can be attributable to both between-study variation AND within-study variation. Hence forth, when we say heterogeneity we refer to the total variation in effects, regardless of whether we attribute it to within-study(sampling error) or between-study(heterogeneity) variance. The reason for doing this is that distinguishing between these sources in psychological settings is incredibly difficult since properly defining the "true" effects we are interested in is very hard. Thus, what we mean by heterogeneity is the total variation of effect sizes expressed through the $\tau^2$ statistic. However, this is not as concrete as it might seem since this statistic needs to be estimated due to it being an unknown parameter. In practice, how this estimation is done depends on the context of our study but generally it is advisable to try multiple estimators(VERONIKI).

# The Causes of Heterogeneity

With our definition of heterogeneity as the total variation of effects, we can add some nuance to its occurrence by viewing it as a counter-factual effect caused by some underlying factors. Exactly what these factors are will be dependent on the field of study you are in, and multiple guidelines of conducting evidence synthesis will use different terminology to refer to these sources. In general, sources of heterogeneity are categorised as stemming from the units under investigation or the methodology used to study those units. In psychology our units of study is almost exclusively humans, thus, all variability in effects attributable to differences in the humans we study is an example of heterogeneity being caused by the units under study. The way we study humans, be that through the design and context of experiments, measurements or modes of inference, is an example of heterogeneity being caused by methodological diversity. It should be noted that the presence of diversity, either in units or method, should not be seen as something that necessitate observed heterogeneity. However, whenever we observe heterogeneity, we must assume it to be caused by either underlying diversity in units and methodology, or through random sampling/variability.

At some point, the observed heterogeneity in a sample of effects becomes so large that the uncertainty with regards to the inferences that can be made about a construct or theory is called into question. In this paper we want to get a better understanding of when this occurs in psychology. To do this we take a look at successful pooling of evidence in meta-analyses, but also at instances where pooling was not possible due to methodological diversity. With this two-pronged approach we aim to paint a nuanced picture of the line that separates qualitative and quantitative evidence synthesis; with the goal of gaining insight into how we can leverage past research for theory building in the present.

